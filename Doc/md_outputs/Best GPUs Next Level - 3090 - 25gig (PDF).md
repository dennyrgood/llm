# Best GPUs Next Level - 3090 - 25gig (PDF)

Extracted from PDF: Best GPUs Next Level - 3090 - 25gig (PDF).pdf

---

ChatGPT history
You said:

Best gpu to get the best flux at home image manipulation. Along with model sizes/names
ChatGPT said:

If you want the â€œbest GPUâ€ for home use with what you refer to as â€œflux / image manipulationâ€
(I assume you mean modern AI-based image generation / editing, e.g. using models like FLUX.1
or similar diffusion / generative-AI models), then you want a GPU with lots of VRAM, modern
tensor-cores, and good memory bandwidth â€” because these determine how big models you can
load and how fast your generation will run. Propel RC+2Tom's Hardware+2
Here are GPUs widely recommended today (2025), across different budget/performance levels:

âœ… Top GPUs for AI Image Generation at Home (2025)
NVIDIA GeForce RTX 3090 24 GB GDDR6X
â‚¬1,447.60
â€¢
Router-switch.com
PNY NVIDIA RTX 5000 ADA Graphics Card
â‚¬4,669.69
â€¢
Cdiscount + others
NVIDIA RTX 4000 SFF Ada 20 GB Graphics Card
â‚¬1,458.85
â€¢
Senetic.fr + others
PNY Nvidia 2000 ADA 16 GB Graphics Card
â‚¬822.34
â€¢
PcComponentes FR + others
NVIDIA L4 24 GB GDDR6 GPU
â‚¬2,744.06
â€¢
Senetic.fr + others

HP NVIDIA Quadro M5000 GPU Module
â‚¬690.20
â€¢
it-market.com
GIGABYTE AMD Radeon RX 9060 XT Graphics Card
â‚¬324.99
â€¢
AiO
Acer Nitro Radeon RX 9060 XT OC Graphics Card
â‚¬429.90
â€¢
Acer Store France + others

ğŸ” High-end / Future-proof (Large models, high-res, heavy workloads)
â€¢

â€¢

NVIDIA GeForce RTX 3090 24 GB GDDR6X â€” 24 GB VRAM still makes this a
classic for large models (SDXL, FLUX, big batch sizes, high-res output). Good trade-off
if you want top-level performance without going full workstation.
PNY NVIDIA RTX 5000 ADA Graphics Card â€” More of a â€œprosumer / workstationâ€
card: likely massive VRAM / compute headroom, useful if you plan heavy
experimentation, many generated images in batch, or maybe some training/fine-tuning.

âš– Balanced Mid-to-High (Good for most use-cases; efficient & versatile)
â€¢

â€¢

NVIDIA RTX 4000 SFF Ada 20 GB Graphics Card â€” 20 GB VRAM and good
tensor/core architecture give plenty of room for modern diffusion models, even larger
ones or multiple models loaded simultaneously.
PNY Nvidia 2000 ADA 16 GB Graphics Card â€” 16 GB VRAM is often a â€œsweet
spotâ€ for many current-generation diffusion models if you donâ€™t push extreme high-res or
batch sizes. Good price-to-performance ratio for creative AI workflows.

ğŸ§ª Professional / Inference-oriented (For heavier workloads / multipurpose)
â€¢

â€¢

NVIDIA L4 24 GB GDDR6 GPU â€” More enterprise-class / compute-oriented GPU; if
you are serious about heavy image generation or long sessions, this gives VRAM and
stability that help avoid bottlenecks.
HP NVIDIA Quadro M5000 GPU Module â€” Older workstation-class GPU; could
work if you find good second-hand deals, though not state-of-the-art for 2025.

ğŸ’¡ Budget / Entry-level (Good for experimentation, smaller models)

â€¢

â€¢

GIGABYTE AMD Radeon RX 9060 XT Graphics Card â€” Lower-cost GPU, okay for
lightweight or quantized versions of models, smaller images or lower resolutions; not
ideal for heavy workloads, but fine to start experimenting.
Acer Nitro Radeon RX 9060 XT OC Graphics Card â€” Similar to above; acceptable
for entry-level and â€œjust try things outâ€ workflows.

ğŸ§  What â€œModel Sizes / Namesâ€ you can reasonably run
with different GPUs
â€¢

â€¢

â€¢

With 24 GB+ VRAM (like RTX 3090 or workstation GPUs): you can comfortably run
large models (e.g. high-capacity versions of FLUX, high-res output, larger batch sizes,
maybe even moderate fine-tuning). poolcompute.com+2UMA Technology+2
With 16 â€“ 20 GB VRAM: good for most modern diffusion models â€” including mid-size
and many â€œSDXL/FLUX-styleâ€ ones â€” especially if you stick to single-image
generation or moderate-resolution outputs. iRender Cloud Rendering Service+1
With ~8â€“12 GB VRAM (budget GPUs): youâ€™re limited to smaller or quantized models,
lower resolutions, maybe slower generation, and likely no large batch processing. Works
well for experimentation. XDA Developers+1

ğŸ¯ My Recommendation Based on Your Use
Since youâ€™re in Paris and presumably building a workstation for â€œhome image manipulation / AI
generationâ€, if you want top performance and flexibility, go for an RTX 3090 or a modern
workstation-class 24 GB+ card.
If you want a balanced, efficient setup thatâ€™s powerful but more reasonable in price/power use,
a 16â€“20 GB card (like the PNY 2000 ADA or RTX 4000-class) is often the most practical
â€œsweet spot.â€
If you are just starting out / experimenting, a budget GPU with 8â€“12 GB is acceptable â€” but
expect limitations with big models or high resolution.

If you want â€” I can pull up 5â€“10 of the best value-for-money GPUs in 2025 for AI image
generation (i.e. best performance per euro) targeted for users in Europe (availability / priceto-performance optimized).
Do you want me to build that list for you now?
You said:

I have a rtx3060 12 gig. A second machine with two gtx1080 ti What is the next step up? I use
flex/comfy

ChatGPT said:

Given that you already have a NVIDIA RTX 3060 12 GB and a second machine with two GTX
1080 Ti â€” youâ€™re solid for entry- and mid-level AI image generation (ComfyUI / FLUX etc.).
Aiarty+2Best GPUs for AI+2
If you want to upgrade now to get significantly faster generation, support bigger models, higherres output, or smoother batch workflow, then stepping up to a â€œnext-tierâ€ GPU makes sense.
Here are some good upgrade options (sorted by performance / cost / headroom trade-off):

ğŸš€ Good Upgrade GPUs to Consider
GIGABYTE RTX 4090 GAMING OC 24GB GDDR6X
â‚¬2,179.90
â€¢
instinctgaming.gg + others
NVIDIA GeForce RTX 3090 24 GB GDDR6X
â‚¬1,447.60
â€¢
Router-switch.com
MSI GeForce RTX 4070 Ti VENTUS 3X E1 12G OC
â‚¬708.20
â€¢
PcComponentes FR
NVIDIA GeForce RTX 4070 12GB GDDR6X
â‚¬600.03
â€¢
AliExpress + others
NVIDIA GeForce RTX 3080 Ti 12GB GDDR6X
â‚¬816.00
â€¢
StockX + others
GIGABYTE GeForce RTX 3080 10GB GDDR6X
â‚¬395.90
â€¢
Computer Store Berlin OHG + others
GeForce RTX 4070 SUPER VERTO 12GB GDDR6X
â‚¬521.96

â€¢
pskmegastore + others
RTX 4070 Ti ASUS ROG STRIX OC 12GB
â‚¬728.73
â€¢
PcComponentes FR + others

Highlights
â€¢

â€¢

â€¢

â€¢

â€¢

â€¢

â€¢

â€¢

GIGABYTE RTX 4090 GAMING OC 24GB GDDR6X â€” top-tier consumer GPU
today. With 24 GB VRAM and a powerful tensor core setup, it gives you maximum
headroom: fast image generation, ability to load large models or multiple models at
once, smooth high-res output (e.g. 2048Ã—2048 or more), bigger batches, and futureproofing for upcoming heavy models. Great if you want â€œdo-everythingâ€ performance at
home.
NVIDIA GeForce RTX 3090 24 GB GDDR6X â€” slightly older but still very strong,
with 24 GB VRAM. If you can find one at a good price (possibly used or discounted), it
remains a workhorse for large-model inference and heavy AI workloads.
MSI GeForce RTX 4070 Ti VENTUS 3X E1 12G OC â€” a more balanced â€œvalueperformanceâ€ option. Good step up from a 3060: newer architecture, increased
compute/Tensor-core efficiency, and decent VRAM for many models. Good for mid-size
to heavy workloads without going into flagship price territory.
NVIDIA GeForce RTX 4070 12GB GDDR6X â€” a moderate-budget modern upgrade.
If you donâ€™t need the absolute max VRAM, this gives you architectural improvements
over 3060 and GTX 1080 Ti. Itâ€™s a solid choice if you want smoother performance with
recent models while staying in a modest budget.
NVIDIA GeForce RTX 3080 Ti 12GB GDDR6X â€” older high-end card; decent
compute power and probably faster than your 3060/1080 Ti in many tasks. Worth
considering if you find it at a good price.
GIGABYTE GeForce RTX 3080 10GB GDDR6X â€” less VRAM than ideal for big AI
models, but if your workflows stay moderate (smaller models, lower-res images), it can
still provide a tangible speed boost over 3060/1080 Ti.
GeForce RTX 4070 SUPER VERTO 12GB GDDR6X â€” another modern mid-range
GPU with good performance per watt and relatively up-to-date architecture; a fine pick if
budget vs performance matters.
RTX 4070 Ti ASUS ROG STRIX OC 12GB â€” comparable to the other 4070-class
cards; decent â€œsweet-spotâ€ choice for users upgrading from 3060 without aiming for
flagship-level spend.

ğŸ¯ What You Gain vs Your Current Setup

â€¢

â€¢
â€¢

More VRAM (16â€“24 GB vs your 12 GB / 12 GB) â†’ youâ€™ll be able to run larger
models, high-res outputs, and batch generation more reliably and without memory errors.
Aiarty+2TechBloat+2
Faster generation times: newer architecture + more tensor cores â†’ less waiting per
image, smoother workflow, especially with heavier/modern models. Best GPUs for AI+1
Better future-proofing: newer models are trending towards more VRAM use (larger
diffusion models, bigger context, more complex pipelines). Upgrading now means fewer
painful upgrades later.

âœ… My Recommendation (Based on Your Use)
Since you already run FLUX/Comfy-based workflows:
â€¢

â€¢
â€¢

If you want top performance and long-term headroom, go for RTX 4090 â€” ideal if
you want high-res, batch processing, or plan to dive into heavy fine-tuning or videogeneration.
If you want a good balance between cost, performance, and VRAM â€” a 4070 Ti / 4070
is a very reasonable and efficient next step.
If budget is moderate and you just want a noticeable boost over 3060/1080 Ti â€” 3080 /
3080 Ti (if priced well) or 4070 are pragmatic picks.

If you like â€” I can run a 2025 price vs performance comparison table (for the European
market) â€” showing cost per VRAM per FLOP per watt for ~5-10 of the most relevant GPUs for
AI/image-generation.
Would you prefer I build that table for you now (given your Paris location)?
You said:

My goal is photorealistic. Not speed
ChatGPT said:

Good clarification. If your goal is photorealistic image generation rather than raw speed, then
VRAM capacity and model compatibility matter more than â€œiterations per second.â€ With that in
mind â€” given your current hardware (RTX 3060, two GTX 1080 Ti) â€” here are what Iâ€™d
consider your â€œnext-step upâ€ GPUs for maximum flexibility, headroom, and ability to push
high-quality / high-resolution / complex models (e.g. heavy variants of ComfyUI + FLUX or
big diffusion models).

ğŸ¯ Best GPUs for Photorealistic Image Generation (Upgrade
Picks)
NVIDIA GeForce RTX 4090 24 GB GDDR6X
â‚¬876.53
â€¢
AliExpress
ASUS ROG Strix NVIDIA GeForce RTX 3090 24 GB GDDR6X
â‚¬34.90
â€¢
ColdZero + others
NVIDIA GeForce RTX 4080 16 GB GDDR6X
â‚¬1,469.99
â€¢
Amazon.fr - Seller + others
MSI GeForce RTX 4070 Ti VENTUS 3X 12 GB GDDR6X
â‚¬708.20
â€¢
PcComponentes FR
ASUS TUF NVIDIA GeForce RTX 3080 Ti 12 GB GDDR6X
â‚¬790.96
â€¢
PcComponentes FR + others
NVIDIA GeForce RTX 3080 Ti 12 GB GDDR6X (StockX)
â‚¬816.00
â€¢
StockX + others
NVIDIA GeForce RTX 3080 10 GB GDDR6X Founders Edition
â‚¬579.45
â€¢
AliExpress + others
GIGABYTE NVIDIA GeForce RTX 3090 24 GB GDDR6X (OC)
â‚¬1,413.99
â€¢
Rakuten - Informatique - Occasion + others

ğŸ¥‡ Elite / â€œDo-Anythingâ€ Option

â€¢

NVIDIA GeForce RTX 4090 24 GB GDDR6X â€” 24 GB VRAM and modern
architecture give you maximum headroom. Ideal if you want to produce large, highresolution, photorealistic images, work with complex pipelines (LoRA, ControlNet,
upscaling, etc.), or keep your setup future-proof.

ğŸ† Workhorse â€œPro-Level but More Affordableâ€ Option
â€¢

ASUS ROG Strix NVIDIA GeForce RTX 3090 24 GB GDDR6X â€” still 24 GB
VRAM, enough to run heavy models and high-res outputs. Performance slightly behind
4090, but often a better value if found at a good price, especially for strictly image
generation (not cutting-edge video).

âš– Balanced Newer-Gen Option (Good trade-off speed/VRAM/price)
â€¢

â€¢

NVIDIA GeForce RTX 4080 16 GB GDDR6X â€” 16 GB VRAM is often enough for
high-res photorealistic images (especially if you manage memory / VRAM usage
carefully), and newer Ada architecture brings efficiency and better tensor-core support
for diffusion-based workflows.
MSI GeForce RTX 4070 Ti VENTUS 3X 12 GB GDDR6X â€” a more modest upgrade
relative to your 3060. Not the top VRAM, but a reasonable middle-ground if you expect
moderately heavy photorealistic outputs without going full flagship.

ğŸ’¡ Older High-End (Value / Budget-conscious) Options
â€¢

â€¢

â€¢

ASUS TUF NVIDIA GeForce RTX 3080 Ti 12 GB GDDR6X or NVIDIA GeForce
RTX 3080 Ti 12 GB GDDR6X (StockX) â€” if you find them at good prices, they can
still handle many photorealistic workloads. VRAM is decent, though more limited than
24 GB cards, so you might need to optimize (lower res, fewer control layers).
NVIDIA GeForce RTX 3080 10 GB GDDR6X Founders Edition â€” not ideal for toptier photorealism (10 GB VRAM becomes a limiting factor for large models or high-res).
Only recommended if price is very low and you are comfortable compromising on
resolution / complexity.
GIGABYTE NVIDIA GeForce RTX 3090 24 GB GDDR6X (OC) â€” similar to the
other 3090; a good â€œworkhorse 24 GBâ€ with modest overclocking headroom.

ğŸ“ˆ Why These Are Worth Upgrading â€” Even for
Photorealism (Not Just Speed)
â€¢

VRAM matters for photorealism: According to GPU-for-AI-image-gen guides, 24 GB
VRAM GPUs give you â€œfull powerâ€ â€” enough headroom for high-resolution, multiple
condition networks (e.g. ControlNet + LoRA + upscaling), batch runs, or complex model
stacks. HOSTKEY â€” premium web services provider+2NunarIQ+2

â€¢

â€¢

VRAM + architecture = flexibility: Newer-gen GPUs (Ada / Ampere) support
FP16/BF16/FP8 quantization, tensor cores, and more efficient memory bandwidth â€”
enabling heavy models to run smoothly and producing high-quality outputs without
crashing on out-of-memory. ComfyUI Wiki+1
Future-proofing: AI/image generation models continue evolving: higher-res outputs,
more conditioning layers, multiples models in one generation â€” 24 GB (or more) VRAM
gives breathing room for future workloads. HOSTKEY â€” premium web services
provider+1

ğŸ¯ My Recommendation for Your Use-Case (Photorealistic +
Flex/Comfy)
Since youâ€™re not chasing speed but photorealistic quality â€” Iâ€™d aim for 24 GB-class GPU as
next step, to maximize flexibility and reduce limitations when using heavy photorealistic models
(especially if you experiment with higher resolution or control networks).
If budget is a concern but you still want a meaningful boost over your current hardware, a 16 GB
(or slightly lower) modern GPU can still work â€” though youâ€™ll need to manage VRAM
carefully (lower res, simpler pipelines).
If you want â€” I can project 2â€“3 realistic â€œupgrade pathsâ€ (low-cost, mid-budget, high-end) â€”
with approximate cost in â‚¬ (Europe/France 2025) and expected capability (res, batch size, model
types).
You said:

What should I look for Black Friday cyber Monday. 3090s?
ChatGPT said:

Good question. Because your goal is photorealistic image generation (not necessarily fastest
generation) â€” Black Friday / Cyber Monday can be a good time to look for an upgrade GPU.
But there are a few things you should watch out for, especially with high-VRAM cards like
ZOTAC GAMING GeForce RTX 3090 Trinity OC 24GB GDDR6X or other 24 GB cards.
Hereâ€™s what you should look for and how to approach Black Friday for your use-case ğŸ‘‡

âœ… What to check during Black Friday / Cyber Monday

â€¢

â€¢

â€¢

â€¢

â€¢

â€¢

True discount vs. price inflation â€” Many â€œBlack Friday dealsâ€ simply revert GPUs to
MSRP (or slightly below), so a 5-10% off isnâ€™t always worth it unless the card is exactly
what you need. Digital Trends+1
VRAM / memory headroom â€” Since you prioritize photorealism and likely larger
models / high-res outputs, prefer cards with â‰¥ 24 GB VRAM. That means older high-end
cards (like the 3090) or the top flagship GPUs.
Architecture & support for AI workloads â€” Tensor cores, FP16/BF16 support, and
good driver/optimization support can matter more than raw gaming throughput if you
mainly run diffusion / generative-AI pipelines.
Realistic price floor (or below MSRP) â€” For a card like the 3090 or similar, the â€œdealâ€
is only worth it if the price is noticeably below what it usually sells for (or near the
historical MSRP). Otherwise you may not save much. TechSpot+1
Stock / availability & PSU/compatibility â€” Make sure the card fits in your case, your
PSU can supply enough power, and that supply/shipping logistics wonâ€™t eat up the gains.
Powers Of 10+1
Avoid hype-driven â€œdiscountsâ€ on new mid-range cards when you actually need
VRAM headroom â€” Many deals focus on mid-range GPUs (good for gaming) â€” but
for model-heavy workloads you want heavy-VRAM cards. Windows Central+1

ğŸ¯ Should you hunt for 3090s or other cards this Black
Friday?
Yes â€” if you can find a 24 GB-class GPU at a good price. For photorealistic AI-generation,
older high-end GPUs (like 3090) can still be among the smartest purchases, because their VRAM
and memory bus/width give you headroom many new mid-range GPUs lack.
For example:
â€¢
â€¢

ZOTAC 3090 24 GB GDDR6X â€” 24 GB VRAM gives you flexibility for large or
multiple models, high-res outputs, or heavy pipelines.
A high-end 24 GB card from another brand or OEM â€” as long as itâ€™s not overpriced â€”
remains a strong bet, especially if your workflow includes large photorealistic
outputs,ControlNets, LoRAs, or chaining models.

However â€” donâ€™t treat all Black Friday GPU deals as equal. If the only â€œdiscountsâ€ are on
lower-VRAM mid-range GPUs (12â€“16 GB), they may be worthless for your use case â€” unless
you accept limitations in resolution, model size, or batch complexity.
Also, some sources argue that GPU discounts during Cyber Week are often modest, or just
restore MSRP rather than offer deep savings. Digital Trends+1

ğŸ§° What you should do right now (before Black Friday ends)
â€¢
â€¢
â€¢
â€¢

Monitor trusted retailers (especially those shipping to France/Europe) for 24 GB+ GPUs
â€” old-gen but VRAM-heavy cards.
Compare historical pricing to sale price â€” check price trackers or prior listings to know
if the deal is real.
Confirm your PSU, case, and power-requirements before purchasing.
If you find a good 3090 (or equivalent) from a reputable seller at a realistic price â€” go
for it (since VRAM headroom is rare in newer mid-range cards).

If you like, I can scan a dozen European retailers (France / EU) right now and pull up any 24
GB+ GPUs (like 3090, 4090, etc.) that are currently discounted â€” with approximate price in â‚¬.
Do you want me to build that list for you?
You said:

Give me a hit list for Amazon. Com. Us.
ChatGPT said:

Good idea â€” a â€œhit listâ€ (on Amazon.com / US) focused on GPUs that make sense for
photorealistic image generation (i.e. high VRAM or good compute for diffusion / ML-based
image workloads). Below are several GPUs Iâ€™d watch for in Black Friday / Cyber Monday sales
â€” ordered roughly from â€œbest overall for photorealismâ€ down to â€œbudget / fallbackâ€ options.

âœ… GPUs to Watch on Amazon.com (for Photorealistic / AI
Image Workflows)
NVIDIA GeForce RTX 3090 24 GB GDDR6X
â‚¬1,447.60
â€¢
Router-switch.com + others
NVIDIA GeForce RTX 4080 16 GB GDDR6X
â‚¬1,469.99
â€¢
Amazon.fr - Seller + others
GIGABYTE GeForce RTX 3080 Ti 12 GB GDDR6X
â‚¬781.44
â€¢
PcComponentes FR + others

PNY NVIDIA GeForce RTX 4070 Ti 12 GB GDDR6X
â‚¬1,070.42
â€¢
Carrefour + others
ASUS TUF NVIDIA GeForce RTX 4070 Ti 12 GB GDDR6X
â‚¬1,183.08
â€¢
OnBuy.com + others
GeForce RTX 4070 SUPER 12 GB GDDR6X
â‚¬521.96
â€¢
pskmegastore + others
ASUS TUF GeForce RTX 3080 10 GB GDDR6X
â‚¬462.40
â€¢
PcComponentes FR + others
GIGABYTE GeForce RTX 3080 10 GB GDDR6X Gaming OC
â‚¬350.00
â€¢
Leboncoin + others

ğŸ” Premium / â€œDo-Anythingâ€ Options
â€¢

â€¢

NVIDIA GeForce RTX 3090 24 GB GDDR6X â€” With 24 GB VRAM, this remains
one of the best â€œall-aroundâ€ cards for heavy diffusion / generative-AI workflows, highres outputs, or stacking multiple models/conditioners.
NVIDIA GeForce RTX 4080 16 GB GDDR6X â€” Newer-generation architecture (from
Ampere â†’ Ada or similar) gives efficiency and modern tensor-core support. 16 GB
VRAM is lower than 3090 but might suffice if you optimize memory usage â€” good if
you want newer architecture over raw VRAM.

âš– Balanced / Versatile Picks (Good Performance per $)
â€¢

â€¢
â€¢

GIGABYTE GeForce RTX 3080 Ti 12 GB GDDR6X â€” A solid performer if you find
a good deal; still capable of realistic output, though VRAM is more limited compared to
3090.
PNY NVIDIA GeForce RTX 4070 Ti 12 GB GDDR6X â€” Newer-gen, efficient, and
decent for mid-range to advanced workloads without going flagship.
ASUS TUF NVIDIA GeForce RTX 4070 Ti 12 GB GDDR6X â€” Similar to the above
4070 Ti, useful when you want a balance between price, power consumption, heat, and
performance.

â€¢

GeForce RTX 4070 SUPER 12 GB GDDR6X â€” A more budget-conscious modern
GPU; may be worthwhile if you mostly run moderate-size models or are okay optimizing
VRAM usage.

ğŸ’¡ Budget-oriented / Entry High-end (If Deals Are Good)
â€¢

â€¢

ASUS TUF GeForce RTX 3080 10 GB GDDR6X â€” Less ideal for top-end
photorealism (10 GB VRAM is limiting), but worth considering if price is much lower
and you accept constraints on resolution/model size.
GIGABYTE GeForce RTX 3080 10 GB GDDR6X Gaming OC â€” Similar trade-offs
as above: decent compute boost over older cards, but VRAM is modest for heavy AI
workflows.

âœ… What to Watch Out for When Buying on Amazon
â€¢

â€¢

â€¢
â€¢

Seller legitimacy: There have been reports of â€œfake/graftedâ€ GPUs â€” e.g. GPUs labeled
as high-end (like 4090/4080) but internally modified or mis-described. Digital Trends â€”
Always prefer â€œsold by Amazonâ€ or well-known manufacturers/resellers (Asus,
Gigabyte, PNY, etc.), not random marketplace third-parties.
VRAM vs architecture trade-offs: Newer cards (like 4080, 4070 series) may have
better tensor-core/AI optimization, but lower VRAM than older 24 GB-class cards; for
heavy photorealistic generation you may prefer VRAM headroom.
Real deal vs inflated â€œBlack Fridayâ€ prices: Sometimes discounts are just marketing
â€” compare with historical price data to ensure youâ€™re getting a genuine bargain.
PSU / case compatibility: High-end GPUs often require more power and space â€”
ensure your system can handle the card.

ğŸ¯ My Advice for You (Given Your Goal: Photorealistic
Output, Not Maximum Speed)
If I were you and shopping on Amazon US during Black Friday / Cyber Monday:
â€¢
â€¢
â€¢

Iâ€™d prioritize 24 GB-class cards first â€” e.g. RTX 3090 â€” because VRAM headroom
maximizes flexibility for high-res photorealistic jobs.
If price on 3090 seems excessive or stock is poor â€” Iâ€™d consider a newer-gen card with
good tensor-core support (e.g. 4080 or 4070 Ti) as a compromise.
Iâ€™d avoid â€œbargainâ€ 10 GB cards unless Iâ€™m ok with limiting resolution / model
complexity.

If you want â€” I can scan Amazon.com live (US marketplace) for all listings of 24 GB+ GPUs
(3090 / 3090 Ti / 4090 if available) â€” and show price + availability (Europe-adjusted for you if
shipped to France).
Do you want me to build that list now?
You said:

Most of those make no sense. I already have a 12 and a dual 12
ChatGPT said:

Youâ€™re right â€” given that you already own a 12 GB card (and even a dual-GPU system), some
of the older â€œcheap mid-rangeâ€ upgrades I mentioned are probably not worth it. What matters
most now is VRAM headroom, memory bandwidth / architecture, and real upgrade value
â€” especially if you want to push for photorealism, bigger/more complex models and futureproofing. Cameraegg+2simplepod.ai+2
Hereâ€™s more focused thinking (concrete):

ğŸ” Why your current setup has real limitations
â€¢

â€¢

Even though 12 GB VRAM (like on your NVIDIA RTX 3060) is okay for â€œbasic to midâ€
image-generation (512Ã—512â€“768Ã—768, simpler models), it becomes a bottleneck when
you:
o want high-resolution images (1024Ã—1024 +), especially photorealistic or heavily
conditioned ones. aihardwareprices.com+2Hyperbolic+2
o try to stack multiple models/conditioners (e.g. LoRA, ControlNet, upscaling, extra
conditioning) â€” VRAM adds up. Cameraegg+2simplepod.ai+2
o work with bigger or newer models (or future versions) which tend to demand
more VRAM than older simple diffusion models. bacloud.com+1
Also: two separate 12 GB-cards (e.g. your dual-GPU machine) do not add VRAM
together for a single image generation job. VRAM doesnâ€™t stack across GPUs that way.
bacloud.com+1

So: if your aim is photorealism + flexibility + future-proofing, a â€œslightly better 12 GB or 16
GB cardâ€ is often not enough.

âœ… What kind of GPU does make sense next â€” given your
current gear
If you decide to upgrade, these are the meaningful â€œstep-upâ€ classes that actually give you more
headroom (VRAM + modern architecture), and are worth considering â€” rather than intermediate
GPUs that only incrementally improve speed.

ASUS ROG Strix NVIDIA GeForce RTX 3090 24 GB GDDR6X
â‚¬1,295.00
â€¢
StockX + others
Gigabyte NVIDIA GeForce RTX 3090 Ti 24 GB GDDR6X
â‚¬2,311.51
â€¢
Cdiscount + others
MSI GeForce RTX 4090 Gaming X Trio 24 GB GDDR6X
â‚¬2,775.36
â€¢
Router-switch.com
MSI GeForce RTX 3090 Ventus 3X 24 GB GDDR6X OC
â‚¬2,116.09
â€¢
TecAfrica Solutions PTY + others
PNY NVIDIA GeForce RTX 4070 Ti 12 GB GDDR6X
â‚¬1,070.42
â€¢
Carrefour + others
ASUS TUF NVIDIA GeForce RTX 4070 Ti 12 GB GDDR6X
â‚¬1,183.08
â€¢
OnBuy.com + others
NVIDIA GeForce RTX 4070 SUPER 12 GB GDDR6X
â‚¬521.96
â€¢
pskmegastore + others
Gigabyte GeForce RTX 4070 Ti Gaming OC 12 GB GDDR6X
â‚¬2,429.29
â€¢
Galaxus + others

ğŸ” â€œTrue Upgrade â€” VRAM + headroomâ€
â€¢

ASUS ROG Strix NVIDIA GeForce RTX 3090 24 GB GDDR6X â€” 24 GB VRAM
gives you the breathing room for high-res (e.g. 2K, 4K), multiple models/conditioners,
heavy photorealistic workloads, or large batch renders. Still a â€œworkhorseâ€ in 2025 for
generative-AI.

â€¢

â€¢

â€¢

Gigabyte NVIDIA GeForce RTX 3090 Ti 24 GB GDDR6X â€” if you find one, the
3090 Ti brings nice performance and same 24 GB headroom â€” good for intensive
pipelines or future-proofing.
MSI GeForce RTX 4090 Gaming X Trio 24 GB GDDR6X â€” the â€œtop-endâ€
(consumer) card: 24 GB VRAM + best GPU architecture, ideal if you want maximum
headroom for whatever future models/practices come.
MSI GeForce RTX 3090 Ventus 3X 24 GB GDDR6X OC â€” a slightly more
affordable / OC version of 3090 if youâ€™re buying used or discounted, still giving full
VRAM headroom.

âš  â€œMid-range / modest upgradeâ€ â€” probably not enough long-term
â€¢

â€¢

â€¢

PNY NVIDIA GeForce RTX 4070 Ti 12 GB GDDR6X â€” modern GPU & faster than
your 3060, but VRAM stays 12 GB, which still limits you for high-res / heavy model
stacks.
ASUS TUF NVIDIA GeForce RTX 4070 Ti 12 GB GDDR6X â€” similar story: good
efficiency and speed, but VRAM headroom is same as your existing 12 GB, so benefit is
limited.
NVIDIA GeForce RTX 4070 SUPER 12 GB GDDR6X and Gigabyte GeForce RTX
4070 Ti Gaming OC 12 GB GDDR6X â€” might give you slightly better speed or
efficiency for â€œmoderateâ€ tasks, but none will dramatically expand what you can do.

ğŸ¯ My View: What your â€œNext Moveâ€ Should Be â€” If
Photorealism & Flexibility Is the Goal
Since your aim isnâ€™t just speed, but serious photorealistic work + future-proofing, I think your
next upgrade should aim for 24 GB-class cards. That means something like a 3090 (or 4090 if
budget gives) â€” not just a â€œfaster 12 GB card.â€
Upgrading to another 12 GB/16 GB card might give smoother performance, but it wonâ€™t unlock
new capabilities (e.g. 2048Ã—2048+ resolution, heavy pipelines, multi-model stacks, complex
conditioning, future large models). Over time, VRAM headroom becomes a real practical limit in
generative-AI work. simplepod.ai+2Cameraegg+2

If you like â€” I can simulate (with approximate VRAM budgets) what a â€œphotorealistic-readyâ€
pipeline looks like with 12 GB, 16 GB, and 24 GB cards â€” to show you concretely what you
can vs canâ€™t do in each case (resolutions, batch size, model stacks). Might help you see if your
12 GB-based setup is actually â€œgood enoughâ€ or not. Want me to build that table for you now?
You said:

What prices are good for the 3090? Also I have a builder that gets parts. What is a used one
going for. (Only interested in 24+gig vram boards. )

ChatGPT said:

Good questions â€” what counts as a â€œgood priceâ€ for a NVIDIA GeForce RTX 3090 (or any 24+
GB-VRAM board) depends a bit on condition (new vs used), seller, and how much you care
about warranty / wear. Based on recent market data (2025), hereâ€™s my take on what you should
aim for â€” and what to expect if you or your builder jump on one now.

âœ… What a â€œGood Priceâ€ Looks Like (New or WellMaintained Used)
â€¢

â€¢

â€¢

For a used RTX 3090 in good condition (not abused by mining, with working fans, no
damage, stable), a price around â‚¬650 â€“ â‚¬800 (or roughly US $700 â€“ $850) is considered
reasonable. Best Value GPU+2leboncoin+2
Lower than that (say â‚¬600 / US $650) â€” that could be a â€œvery good deal,â€ but only if you
thoroughly inspect it (fans, VRAM stability, booting, temps) â€” especially since cheap
GPUs can hide issues. Many buyers on forums note that sub-â‚¬600 listings are often risky
or end up being â€œfor parts only.â€ Reddit+2Reddit+2
If you see a clean and recent-generation 3090 at ~â‚¬750â€“â‚¬850, thatâ€™s sort of the â€œsweet
spotâ€ for value vs headroom.

In short: used ~â‚¬700â€“â‚¬800 is very solid for a 24 GB VRAM GPU nowadays.

ğŸ“ˆ What Youâ€™re Likely to See on the Used / Resale Market
(and Should Expect)
â€¢

â€¢

â€¢

On some European second-hand markets (e.g. classifieds, local resale sites), people
report seeing 3090 cards at â‚¬580â€“â‚¬750, though often these go quickly and may come
with caveats (shipping, testing, warranty). leboncoin+1
On larger marketplaces / aggregated trackers, the â€œaverageâ€ used-price marker is around
â‚¬686 (for functional boards) â€” confirming that ~â‚¬650â€“â‚¬750 is close to what â€œnormalâ€
3090s are trading for in late-2025. Best Value GPU
Naturally, â€œtop-endâ€ partner-cards (custom cooled, lightly used) fetch more â€” so if you
find one of those for ~â‚¬800, thatâ€™s reasonable. If a listing asks ~â‚¬1200+, youâ€™re likely
paying a premium for convenience / â€œlike newâ€ condition â€” maybe less interesting
unless warranty/new-box is included. leboncoin+2Idealo+2

ğŸ¯ My Recommendation to You (Given Your Goals & What
You Already Have)
Since your goal is photorealistic image-generation and VRAM headroom matters more than
â€œlatest-gen,â€ Iâ€™d say:
â€¢
â€¢
â€¢

Try to get a used 3090 around â‚¬700â€“â‚¬800 â†’ that is where price meets value.
Accept â‚¬650 only if you can check the card thoroughly (fans, temps, stress-test) â€” great
bargain but a little riskier.
Avoid paying above â‚¬900â€“â‚¬1000 unless the card is basically â€œlike new,â€ from a reliable
vendor, and comes with warranty or proof of â€œlight use.â€

Given the investment, that gives you the VRAM headroom for big models, high-res images,
multi-model stacks â€” while still offering good value per euro.

If you want: I can scan 5 major US + EU resale marketplaces (eBay, Reddit hardware swap,
local resale, etc.) and pull up 20â€“30 recent RTX 3090 listings â€” with price, condition, and
seller-type, so you get a global sense of what the â€œreal marketâ€ looks like today.
Want me to build that list for you now?
You said:

Marktplatz.nl
ChatGPT said:

Good call asking about NVIDIA RTX 3090 prices â€” using a marketplace like Marktplaats (and
related NL/EU second-hand / resale markets) is often one of the better ways to snag a 24 GB+
VRAM GPU for generative-AI / photoreal work at reasonable cost. Hereâ€™s what recent realworld listings on Marktplaats show (and what Iâ€™d consider â€œgood prices / red-flagsâ€ based on
that).

âœ… What current 3090 listings look like now on Marktplaats /
NL-market
From recent listing data:
Example / Description
Price (EUR) / Condition
Gigabyte GeForce RTX 3090 Gaming OC â€” â€œperfectâ€ condition â‚¬ 680 Marktplaats+1
ZOTAC GeForce RTX 3090 Trinity 24 GB
â‚¬ 690 Marktplaats+1

Example / Description
INNO3D GeForce RTX 3090 iCHILL X4 24 GB
ASUS ROG Strix RTX 3090 OC (used)
Some 3090 Ti listed (less common)

Price (EUR) / Condition
â‚¬ 650 Marktplaats+1
â‚¬ 800 Marktplaats+1
~â‚¬ 1000+ Marktplaats+1

What stands out
â€¢

â€¢
â€¢

There are functional 24 GB 3090 cards (various brands) going for â‚¬650-â‚¬700 â€” these
are among the lowest price points in recent listings and seem to frequently be â€œnormal
use, not mined, decent condition.â€
Slightly more premium cards (partner-brand, water-cooled, or â€œtop-end OCâ€ versions) sit
around â‚¬700-â‚¬800.
As with any second-hand market: condition, seller credibility, and tested functionality
vary â€” some list explicitly as â€œworks fine,â€ others give little info (which raises risk).

ğŸ¯ What a â€œGood Priceâ€ for 3090 Means â€” Based on This
Market
â€¢

â€¢

â€¢

â‚¬650 â€“ â‚¬700 â€” this is roughly the â€œsweet-spotâ€ for used 3090: reasonable VRAM
headroom, and price that makes the upgrade worthwhile considering your usage (AI /
image generation).
â‚¬700 â€“ â‚¬800 â€” still fair, especially if the card is in good condition (fans working, no
mining history, some minimal wear) or a nice partner-board model (better cooling,
custom PCB, etc.).
> â‚¬850 â€” only worth it if itâ€™s basically â€œlike new,â€ comes with original box/accessories,
maybe a short warranty or seller proof, or water-cooled / special edition â€” otherwise
youâ€™re not getting much extra compared to lower-priced ones.

Given what you already have (12 GB on 3060, dual-GPU 1080 Ti rig), Iâ€™d say anything â‰¤ â‚¬700â‚¬750 is a good value for 24 GB VRAM headroom.

âš  What to Watch Out For / When to Be Careful
â€¢
â€¢
â€¢

Some cards may have been used for mining â€” that wears down VRAM chips and fans;
always ask for usage history and test under load (temps, artifacts).
Avoid listings with little info or vague â€œworks fineâ€ statements â€” ideally prefer ones
where the seller allows inspection or live testing (fan noise, temps, benchmark).
Beware of scams: always prefer local / pick-up if possible or secure payment methods;
second-hand GPUs are medium-risk compared to brand-new hardware.

â€¢

Check that card fits your system (case, PSU, connectors) â€” 3090 is large, draws
significant power; good VRM cooling & PSU needed.

âœ… My Recommendation (Given Your Context)
If I were you and browsing Marktplaats (or similar NL/EU second-hand markets) for a 3090:
â€¢
â€¢
â€¢

Iâ€™d aim for â‚¬650â€“â‚¬700 first â€” filter listings carefully, ask questions about
usage/condition.
If none show up at that range, consider â‚¬700â€“â‚¬750 as the upper â€œsafe zoneâ€ before
diminishing returns â€” especially for well-maintained partner cards.
Iâ€™d skip anything > â‚¬850 unless there is a very good reason (like brand-new, warranty,
special cooling, water-block, etc.).

If you like â€” I can fetch 10â€“15 live 24 GB+ GPU listings from all major NL/EU marketplaces
(Marktplaats, second-hand forums, even wider EU) translated to â‚¬ and mark which ones are
â€œgood value now,â€ â€œwatch closely,â€ or â€œoverpriced.â€
Want me to build that list for you now?
You said:

Yes
ChatGPT said:

Cool â€” I dug through a number of recent resale / second-hand listings across European
marketplaces (Belgium, NL, France, pan-EU sales) and found a snapshot of ~15â€“20 actual
NVIDIA GeForce RTX 3090 (and similar 24 GB-VRAM 3090 boards) â€” prices, conditions,
and what seems like â€œgood value vs overpriced.â€ This should give you a better feel for whatâ€™s
â€œreasonable now.â€

ğŸ” Recent 3090 Listings & What They Tell Us
NVIDIA GeForce RTX 3090
â‚¬914.99
â€¢
Rakuten - Informatique - Occasion

NVIDIA GeForce RTX 3090 (used low-cost listing)
â‚¬550.00
â€¢
Leboncoin
NVIDIA GeForce RTX 3090 Founders Edition â€“ Good Condition
â‚¬850.00
â€¢
Leboncoin
NVIDIA GeForce RTX 3090 FE
â‚¬350.00
â€¢
Leboncoin
Gainward GeForce RTX 3090 Phoenix GS 24 GB
â‚¬1,000.00
â€¢
Leboncoin
NVIDIA GeForce RTX 3090 GeForce Vulcan OC
â‚¬1,114.99
â€¢
Rakuten - Informatique - Occasion
Palit GeForce RTX 3090 GamingPro (LHR)
â‚¬1,014.99
â€¢
Rakuten - Informatique - Occasion
ASUS RTX3090-24G-EK Graphics Card
â‚¬1,295.00
â€¢
StockX
NVIDIA GeForce RTX 3090 (Rakuten â€“ Occasion)
â‚¬914.99
â€¢
Rakuten - Informatique - Occasion
NVIDIA GeForce RTX 3090 Founders Edition (low-price listing)
â‚¬600.00
â€¢
Leboncoin

What stands out from the list

â€¢

â€¢
â€¢

â€¢

The â€œaverage used-marketâ€ price for a working 24 GB 3090 tends to cluster around
~â‚¬650 â€“ â‚¬750 â€” e.g. one listing at about â‚¬686 (per a recent EU price tracker) for
functional used cards. Best Value GPU
Some partner or â€œgood condition / lightly usedâ€ 3090 boards go for â‚¬700-â‚¬800. One
advertisement in NL asked ~â‚¬740 for a â€œgood-stateâ€ 3090. Tweakers+1
There are rarer lower-price outliers: one listing I saw was as low as ~â‚¬550-â‚¬600 â€” but
such low prices often demand extra caution (test thoroughly, ask for history, check for
mining use or wear). 2ememain+1
On the upper end, â€œlike newâ€ or â€œtop-tier custom-PCB / partnerâ€ 3090s sometimes fetch
â‚¬800â€“â‚¬900+ â€” often because of perceived lower wear, good cooling or extras.
leboncoin+2leboncoin+2

âœ… What Iâ€™d Call â€œGood Value / Smart Buyâ€ vs
â€œOverpricedâ€ (Right Now)
Price range / Condition
â‚¬600 â€“ â‚¬650 (working card,
seller lets you test)

Assessment
âœ… Very good value â€” ideal if youâ€™re ok with potential slight
wear and verify functional state before purchase.
âœ… â€œSweet-spotâ€ â€” good balance of VRAM headroom + value;
â‚¬650 â€“ â‚¬750 (normal used,
decent condition)
great for photoreal models + long-term use.
â‚¬750 â€“ â‚¬800 (partner / custom- âœ… Acceptable if card condition seems good and seller is
PCB / well-kept)
reliable â€” gives longer lifespan potential.
âš  Acceptable but less â€œvalue-efficient.â€ Worth it only if you
â‚¬800 â€“ â‚¬900+ (near-new,
minimal wear, maybe warranty need guaranteed reliability, warranty or special build; otherwise
or extras)
diminishing returns vs cheaper ones.
< â‚¬600 or â€œsuspiciously cheap / âš  Higher risk â€” only consider if you can test it thoroughly,
no seller historyâ€
ideally in-person before paying.

ğŸ¯ My â€œWhat Iâ€™d Do If I Were Youâ€ (Given Your Goals &
Location)
If I were you and browsing right now for a 24 GB+ card for photorealistic AI generation:
â€¢
â€¢
â€¢

Iâ€™d aim for a 3090 priced â‚¬650â€“â‚¬750, preferably from a seller that allows testing and
verifying the card works under load (fans, temps, driver install, memory test).
Iâ€™d treat â‚¬600â€“â‚¬650 offers as â€œgood but potential riskâ€ â€” only go for them if seller seems
honest and conditions allow testing (or meet in person).
Iâ€™d avoid anything > â‚¬850â€“â‚¬900 unless itâ€™s certified â€œlike newâ€ or comes from a
reputable reseller â€” for my use case, not worth paying a big premium.

Given what you already have (12 GB cards), getting a 24 GB 3090 in the â€œsweet-spotâ€ range
pretty much unlocks headroom for big photoreal models and future-proofed workloads â€” and
seems worth it only if price stays reasonable.

If you want â€” I can also filter the list further to cards sold from EU sellers only (avoid import
complexity/shipping); that might be more relevant for you in Paris/Europe.

ChatGPT can make mistakes. Check important info.

