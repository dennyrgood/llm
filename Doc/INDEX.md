# Project Docs Index

This index groups and briefly describes documentation in this repository. Use it as a starting table-of-contents. If you'd like, run `tools/generate_doc_index.py` to auto-generate or update a more detailed index.

## Guides (setup, long-form)
- [GROK.Ollama.on.Win11.Ultimate.Perf.Guide.md](https://github.com/dennyrgood/LLM/blob/main/Doc/GROK.Ollama.on.Win11.Ultimate.Perf.Guide.md) — Windows 11 + Ollama GPU guide, RTX 3060 tips, quantization, monitoring and OpenWebUI integration.
- [New RTX 3060 Setup - SETTING_UP_REAL_IMAGE_MANIPULATION_LOCAL_SERVER.md](https://github.com/dennyrgood/LLM/blob/main/Doc/New%20RTX%203060%20Setup%20-%20SETTING_UP_REAL_IMAGE_MANIPULATION_LOCAL_SERVER.md) — ComfyUI + Flux image pipeline step-by-step.
- [Using 1040 until 3060 Gets Here](https://github.com/dennyrgood/LLM/blob/main/Doc/Using%201040%20until%203060%20Gets%20Here) — Practical advice while you wait for GPU upgrade.
- [Claude session - started the whole rabbit trail of hosting my own LLM.md](https://github.com/dennyrgood/LLM/blob/main/Doc/Claude%20session%20-%20started%20the%20whole%20rabbit%20trail%20of%20hosting%20my%20own%20LLM.md) — collection of Ollama tips, aliases, CLI examples and tooling.

## Quick References / Cheat Sheets
- [Quantization & Context Tokens — A One‑Page Practical Guide.md](https://github.com/dennyrgood/LLM/blob/main/Doc/Quantization%20%26%20Context%20Tokens%20%E2%80%94%20A%20One%E2%80%91Page%20Practical%20Guide.md) — token heuristics and quantization labels (Q4_K_M, Q4_0 etc).
- [Quantization and Context Tokens — One‑Page Guide.html](https://github.com/dennyrgood/LLM/blob/main/Doc/Quantization%20and%20Context%20Tokens%20%E2%80%94%20One%E2%80%91Page%20Guide.html) — the same guide in HTML for quick viewing.
- [LLM QUICK SELECTION GUIDE.txt](https://github.com/dennyrgood/LLM/blob/main/Doc/LLM%20QUICK%20SELECTION%20GUIDE.txt) — short "which model for what" cheat sheet.

## Models / Model Inventory
- [Ollama Models as of 2025 11 18](https://github.com/dennyrgood/LLM/blob/main/Doc/Ollama%20Models%20as%20of%202025%2011%2018) — overview of installed and available models and operational notes.
- [GROK.recommended.llms.w.RTX.3060.txt](https://github.com/dennyrgood/LLM/blob/main/Doc/GROK.recommended.llms.w.RTX.3060.txt) — recommended models for RTX 3060 and suggested pulls.
- [GROK.recommended.nano.banana.replacement.txt](https://github.com/dennyrgood/LLM/blob/main/Doc/GROK.recommended.nano.banana.replacement.txt) — image workflow and ComfyUI/Flux recommendations.
- [ollama-ls.txt](https://github.com/dennyrgood/LLM/blob/main/Doc/ollama-ls.txt) — `ollama ls` output (installed models + sizes).
- [ollama-show-out.txt](https://github.com/dennyrgood/LLM/blob/main/Doc/ollama-show-out.txt) — results of `ollama show` calls for various models.

## Workflows & Automation
- [OpenWebUI — Task Scheduler CLI Reference.txt](https://github.com/dennyrgood/LLM/blob/main/Doc/OpenWebUI%20%E2%80%94%20Task%20Scheduler%20CLI%20Reference.txt) — Run OpenWebUI at startup via Task Scheduler; includes run script example and troubleshooting.
- [What to Try Next.txt](https://github.com/dennyrgood/LLM/blob/main/Doc/What%20to%20Try%20Next.txt) — short list of next run commands and experiments.

## Scripts & Batches
- [ollama-show.bat](https://github.com/dennyrgood/LLM/blob/main/Doc/ollama-show.bat) — batch showing several `ollama show` commands and sample usage.
- [a](https://github.com/dennyrgood/LLM/blob/main/Doc/a) — small file (appears to be binary/encoded text listing `ollama show` commands).

---

If anything here is in the wrong category, tell me and I'll move it.  
If you prefer fewer categories (e.g. Guides + Scripts + Models only) I can compress them.
